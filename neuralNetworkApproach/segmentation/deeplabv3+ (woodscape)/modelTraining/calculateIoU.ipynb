{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import jaccard_score\n",
        "import tarfile\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import functional as F\n",
        "from albumentations import Compose, Normalize, HorizontalFlip, RandomCrop\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "# Путь к архиву\n",
        "archive_path = 'val.zip'\n",
        "# Путь, куда распаковать\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Проверяем, существует ли папка для извлечения\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "# Распаковка архива\n",
        "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Архив разархивирован.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rliv0KUIRhwC",
        "outputId": "4ee49180-3526-4150-82ad-f99989e5663d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Архив разархивирован.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_ds_store_files(directory):\n",
        "    \"\"\"\n",
        "    Удаляет все файлы .DS_Store в указанной директории и её подкаталогах.\n",
        "    \"\"\"\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file == '.DS_Store':\n",
        "                file_path = os.path.join(root, file)\n",
        "                os.remove(file_path)\n",
        "                print(f\"Удалён файл: {file_path}\")\n",
        "\n",
        "image_dir = '/content/val/valImages'\n",
        "remove_ds_store_files(image_dir)\n",
        "\n",
        "image_dir = '/content/val/valLabels'\n",
        "remove_ds_store_files(image_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuDVIv1EUNJH",
        "outputId": "5c21bf97-0da5-455d-cdf6-97ac4a04e106"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Удалён файл: /content/val/valImages/.DS_Store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# --- Параметры ---\n",
        "IMAGE_DIR = \"val/valImages\"  # Путь к папке с изображениями\n",
        "LABEL_DIR = \"val/valLabels\"  # Путь к папке с масками\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 2  # Два класса: разметка или нет разметки\n",
        "NUM_EPOCHS = 25\n",
        "ACCUMULATION_STEPS = 4  # Для градиентного накопления\n",
        "LEARNING_RATE = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Кастомный Dataset ---\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.image_files = self._get_image_files(image_dir)\n",
        "        self.label_files = self._match_label_files(self.image_files, label_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _get_image_files(self, image_dir):\n",
        "        \"\"\"\n",
        "        Возвращает список изображений, игнорируя ненужные файлы, например, .DS_Store.\n",
        "        \"\"\"\n",
        "        image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg')) and not f.startswith('.')]\n",
        "        return sorted(image_files)\n",
        "\n",
        "    def _match_label_files(self, image_files, label_dir):\n",
        "        \"\"\"\n",
        "        Фильтрует файлы масок, оставляя только те, которые соответствуют изображениям.\n",
        "        \"\"\"\n",
        "        valid_files = []\n",
        "        for image_file in image_files:\n",
        "            label_file = image_file.replace(\"_prev\", \"\")\n",
        "            label_path = os.path.join(label_dir, label_file)\n",
        "            if os.path.exists(label_path):\n",
        "                valid_files.append(label_file)\n",
        "        return valid_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label_file = self.label_files[idx]\n",
        "        image_file = label_file.replace(\".png\", \"_prev.png\")\n",
        "\n",
        "        image_path = os.path.join(self.image_dir, image_file)\n",
        "        label_path = os.path.join(self.label_dir, label_file)\n",
        "\n",
        "        try:\n",
        "            # Загрузка изображения и маски\n",
        "            image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "            label = np.array(Image.open(label_path))\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image or label: {e}\")\n",
        "            return None, None\n",
        "\n",
        "        # Преобразование маски: выделение только класса (0, 0, 255)\n",
        "        label = self._convert_to_binary_mask(label)\n",
        "\n",
        "        # Применение трансформаций\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=label)\n",
        "            image = augmented[\"image\"]\n",
        "            label = augmented[\"mask\"]\n",
        "\n",
        "        return image, label.long()\n",
        "\n",
        "    @staticmethod\n",
        "    def _convert_to_binary_mask(label):\n",
        "        \"\"\"\n",
        "        Преобразует маску в бинарный формат:\n",
        "        - Все пиксели с цветом (0, 0, 255) становятся 1 (разметка).\n",
        "        - Остальные пиксели становятся 0 (фон).\n",
        "        \"\"\"\n",
        "        binary_mask = np.zeros(label.shape[:2], dtype=np.uint8)\n",
        "        binary_mask[(label[:, :, 0] == 0) & (label[:, :, 1] == 0) & (label[:, :, 2] == 255)] = 1\n",
        "        return binary_mask\n",
        "# --- Определение модели ---\n",
        "def initialize_model(num_classes=2, pretrained=True):\n",
        "    model = deeplabv3_resnet50(pretrained=pretrained)\n",
        "    model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "    return model\n",
        "\n",
        "# --- Функция для расчета IoU ---\n",
        "def calculate_iou(pred_mask, true_mask):\n",
        "    # Преобразуем маски в 1D массивы\n",
        "    pred_mask = pred_mask.flatten()\n",
        "    true_mask = true_mask.flatten()\n",
        "    # Используем jaccard_score для расчета IoU\n",
        "    return jaccard_score(true_mask, pred_mask)\n",
        "\n",
        "# --- Расчет IoU ---\n",
        "def evaluate_iou(model, image_dir, label_dir, device):\n",
        "    model.eval()\n",
        "    iou_scores = []\n",
        "\n",
        "    image_files = sorted(os.listdir(image_dir))\n",
        "    label_files = sorted(os.listdir(label_dir))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image_file, label_file in zip(image_files, label_files):\n",
        "            image_path = os.path.join(image_dir, image_file)\n",
        "            label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "            # Загрузка изображения и маски\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            label = np.array(Image.open(label_path))\n",
        "\n",
        "            # Преобразуем метку в бинарную маску\n",
        "            true_mask = CustomDataset._convert_to_binary_mask(label)\n",
        "\n",
        "            # Применяем преобразования\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((2048, 2048)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "            # Прогнозирование\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                output = model(input_tensor)[\"out\"]\n",
        "\n",
        "            probabilities = torch.sigmoid(output)\n",
        "            threshold = 0.32\n",
        "            pred_mask = probabilities[0, 1, :, :].cpu().numpy() > threshold\n",
        "\n",
        "            # Приводим предсказанную маску к размеру истинной маски\n",
        "            pred_mask_resized = cv2.resize(pred_mask.astype(np.float32), (true_mask.shape[1], true_mask.shape[0]))\n",
        "            pred_mask_resized = pred_mask_resized > threshold\n",
        "\n",
        "            # Вычисление IoU\n",
        "            iou = calculate_iou(pred_mask_resized, true_mask)\n",
        "            iou_scores.append(iou)\n",
        "\n",
        "    # Усредненный IoU\n",
        "    mean_iou = np.mean(iou_scores)\n",
        "    return mean_iou\n",
        "\n",
        "# --- Основная часть кода ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_PATH = \"deeplabv3p_epoch20.pth\"  # Путь к модели\n",
        "\n",
        "# Инициализация модели\n",
        "model = initialize_model(num_classes=2, pretrained=False)\n",
        "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "\n",
        "# Загрузка состояния модели\n",
        "filtered_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict()}\n",
        "model.load_state_dict(filtered_state_dict, strict=False)\n",
        "\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# --- Расчет IoU ---\n",
        "mean_iou = evaluate_iou(model, IMAGE_DIR, LABEL_DIR, DEVICE)\n",
        "print(f\"Средний IoU: {mean_iou:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R08Pua5nSOqt",
        "outputId": "2f389f34-7e94-4397-9a7d-a91aa43d5b6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead. warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`. warnings.warn(msg)\n",
            "<ipython-input-8-fb0433df0095>:148: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature. state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
            "Средний IoU: 0.7923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1eTBiRzkWMVR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}